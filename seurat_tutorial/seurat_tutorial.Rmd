---
title: "Seurat tutorial"
author: "Georgia Miller"
date: "2024-10-24"
output: github_document 
---

## This is following the Seurat tutorial from https://satijalab.org/seurat/articles/pbmc3k_tutorial

This is to analyse a dataset of Peripheral Blood Mononuclear Cells (PBMCs) available from 10X genomics. 2,700 single cells were sequenced on Illumina NextSeq500.

```{r setup, include=FALSE}
library(dplyr)
library(Seurat)
library(patchwork)
```

# Read in data
Read10X reads in output of the cellranger pipeline form 10X, returns Unique Molecular Identified (UMI) count matrix. Values in matrix represents number of molecules for each feature (gene, row) detected in each cell (column). More recent versions use h5 file format, read in using Read10X_h5() function. 
```{r}
# Load the PBMC dataset
pbmc.data <- Read10X(data.dir = "/Users/k2477939/Documents/myrepo/seurat_tutorial/filtered_gene_bc_matrices/hg19/")
```

## Set up Seurat object
Use count matrix to create a Seurat object which is a container for both data (e.g. count matrix) and analysis (PCA, clustering results) for sc-dataset.
```{r}
# Initialise Seurat object with raw non-normalised data. 
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
pbmc
```

## Examine data
Examine count matrix data. 
. values are 0s, this sparse-matrix representation saves memory and speed
```{r}
# Examine some genes in the first 30 cells
pbmc.data[c("CD3D", "TCL1A", "MS4A1"), 1:30]

# Sparse size
object.size(as.matrix(pbmc.data))

# Dense size
object.size(pbmc.data)
```


# Pre-processing

## QC and selecting cells for further analysis
Common QC metrics include

  * No. of unique genes detected in each cell
    + low-quality cells or empty droplets often have very few genes
    + cell doublets or multiplets may have aberrantly high gene count
  
  * total no. molecules detected in a cell
    + correlates strongly with unique genes
    
  * percentage of reads that map to the mitochondrial contamination
    + low-quality/dying cells often have extensive mt contamination
    + calculates percentage of counts originates from a set of features with PercentageFeatureSet()
    + set of all genes starting with MT- used as set of mt genes
    
Find no. unique genes and total molecules in the object metadata as they are automatically calculated in CreateSeuratObject()
```{r}
 # For first 5 cells
head(pbmc@meta.data, 5)
```
Use PercentageFeatureSet() to find mt contamination. Add column to object metadata using [[
```{r}
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
```


## Visualise QC metrics
  * Violin plot
```{r fig.width = 10, fig.height = 7}
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, alpha = 0.5)
```

  * Feature scatter
```{r fig.width = 10, fig.height = 5}
plot1 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(pbmc, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2
```

## Filter cells
Filter cells based on QC metrics e.g. here keep cells with 200-2,500 unique features and with <5% mitochondrial counts.
```{r}
pbmc <- subset(pbmc, subset = nFeature_RNA > 200  & nFeature_RNA < 2500 & percent.mt < 5)
```


# Normalise the data
By default, use a global-scaling normalisation method "LogNormalize" that normalises feature expression measurements for each cell by total expression, multiplies by a scale factor (default 10,000) and log-transforms the result. Normalised values are stored in pbmc[["RNA"]]$data in Seurat v5.

```{r}
# Extra arguments here are not needed as using default
pbmc <- NormalizeData(pbmc, normalization.method = "LogNormalize", scale.factor = 10000)
```
Assumes each cell originally contains the same number of RNA molecules. Alternative workflows do not assume this e.g. SCTransform()

# Feature selection

Next, we calculate a subset of features that exhibit high cell-to-cell variation in in the dataset. Have found that focusing on these downstream helps to highlight biological signal in sc datasets.

FindVariableFeatures() function has improved on previous versions by directly modelling the mean-variance relationship inherent in sc data. 

  * Variance-stabilising transformation to correct for the mean-variance relationship inherent to sc RNA-seq. If only choose genes based on log-norm sc variance would not account for this
    + mean and variance of each gene in unnorm data, apply lg10-transformation, fit a curve to predict variance of each gene as a function of its mean (local fitting of polynomials of degree 2). Provides a regularised estimator of variance given then mean of a feature so can use it to standardise feature counts without removing higher-than-expected variation.
  * Transformation:
    + where F = feature, V = value, sd = standard deviation, C = cell
    standardised V of Fi in Cj = (raw V of Fi in Cj - mean raw V of Fi)/expected sd of Fi from global mean variance fit
    + clipped standardised values to max root of total number of cells
    + found variance of standardised values across all cells, this variance is a measure of sc dispersion after controlling for mean exp, used to directly rank the features
    + by default, returns 2,000 features per dataset with the highest standardised variance
  * If multiple datasets integrated
    + feature selection on individual datasets as above
    + give priority to features that are highly variable in multiple experiments
    + take top 2,000 for downstream analysis
    + broke ties by examining ranks of tied features in each original dataset and take those with the highest median rank SelectIntegrationFeatures()

```{r fig.width = 15, fig.height = 5}
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)

# Identify 10 most highly variable genes
top10 <- head(VariableFeatures(pbmc), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(pbmc)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```
# Scaling

Apply a linear transformation (scaling) is a standard pre-processing step to dimensionality reduction tehcnqiues

ScaleData() does:

  * shifts exp of each gene so mean across all is 0 and variance is 1
    + gives equal weight to genes in downstream analyses so highly expressed genes do not dominate
  * stores results in pbmc[["RNA"]]$scale.data
  * only variable features are scaled by default
  * specify features argument to scale additional features

```{r}
all.genes <- rownames(pbmc)
pbmc <- ScaleData(pbmc, features = all.genes)
```

Can also remove unwanted sources of variation from a dataset. E.g. could 'regress out' heterogeneity associated with e.g. cell cycle stage or mt contamination

But, recommend SCTransform() for advanced users
```{r}
#pbmc <- ScaleData(pbmc, vars.to.regress = "percent.mt")
```

# Linear dimensional reduction

Perform PCA on scaled data. By default, use previously determined variable features but can define different subset using features (must pass through ScaleData first)

For first PCs, outputs a list of genes with most positive and most negative loadings, representing modules of genes with correation or anti-correlation across scs

```{r}
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
```


